{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 394), (506691, 393))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transaction = pd.read_csv('Fraud/train_transaction.csv')\n",
    "test_transaction = pd.read_csv('Fraud/test_transaction.csv')\n",
    "train_identity = pd.read_csv('Fraud/train_identity.csv')\n",
    "test_identity = pd.read_csv('Fraud/test_identity.csv')\n",
    "\n",
    "train_transaction.shape, test_transaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 434), (506691, 433))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test_df = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n",
    "\n",
    "del train_identity, train_transaction, test_transaction, test_identity\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = train_df.columns.drop('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionAmt_to_mean_card1'] = train_df['TransactionAmt'] / train_df.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_mean_card4'] = train_df['TransactionAmt'] / train_df.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_std_card1'] = train_df['TransactionAmt'] / train_df.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train_df['TransactionAmt_to_std_card4'] = train_df['TransactionAmt'] / train_df.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test_df['TransactionAmt_to_mean_card1'] = test_df['TransactionAmt'] / test_df.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_mean_card4'] = test_df['TransactionAmt'] / test_df.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_std_card1'] = test_df['TransactionAmt'] / test_df.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test_df['TransactionAmt_to_std_card4'] = test_df['TransactionAmt'] / test_df.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "train_df['id_02_to_mean_card1'] = train_df['id_02'] / train_df.groupby(['card1'])['id_02'].transform('mean')\n",
    "train_df['id_02_to_mean_card4'] = train_df['id_02'] / train_df.groupby(['card4'])['id_02'].transform('mean')\n",
    "train_df['id_02_to_std_card1'] = train_df['id_02'] / train_df.groupby(['card1'])['id_02'].transform('std')\n",
    "train_df['id_02_to_std_card4'] = train_df['id_02'] / train_df.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test_df['id_02_to_mean_card1'] = test_df['id_02'] / test_df.groupby(['card1'])['id_02'].transform('mean')\n",
    "test_df['id_02_to_mean_card4'] = test_df['id_02'] / test_df.groupby(['card4'])['id_02'].transform('mean')\n",
    "test_df['id_02_to_std_card1'] = test_df['id_02'] / test_df.groupby(['card1'])['id_02'].transform('std')\n",
    "test_df['id_02_to_std_card4'] = test_df['id_02'] / test_df.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train_df['D15_to_mean_card1'] = train_df['D15'] / train_df.groupby(['card1'])['D15'].transform('mean')\n",
    "train_df['D15_to_mean_card4'] = train_df['D15'] / train_df.groupby(['card4'])['D15'].transform('mean')\n",
    "train_df['D15_to_std_card1'] = train_df['D15'] / train_df.groupby(['card1'])['D15'].transform('std')\n",
    "train_df['D15_to_std_card4'] = train_df['D15'] / train_df.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test_df['D15_to_mean_card1'] = test_df['D15'] / test_df.groupby(['card1'])['D15'].transform('mean')\n",
    "test_df['D15_to_mean_card4'] = test_df['D15'] / test_df.groupby(['card4'])['D15'].transform('mean')\n",
    "test_df['D15_to_std_card1'] = test_df['D15'] / test_df.groupby(['card1'])['D15'].transform('std')\n",
    "test_df['D15_to_std_card4'] = test_df['D15'] / test_df.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train_df['D15_to_mean_addr1'] = train_df['D15'] / train_df.groupby(['addr1'])['D15'].transform('mean')\n",
    "train_df['D15_to_mean_addr2'] = train_df['D15'] / train_df.groupby(['addr2'])['D15'].transform('mean')\n",
    "train_df['D15_to_std_addr1'] = train_df['D15'] / train_df.groupby(['addr1'])['D15'].transform('std')\n",
    "train_df['D15_to_std_addr2'] = train_df['D15'] / train_df.groupby(['addr2'])['D15'].transform('std')\n",
    "\n",
    "test_df['D15_to_mean_addr1'] = test_df['D15'] / test_df.groupby(['addr1'])['D15'].transform('mean')\n",
    "test_df['D15_to_mean_addr2'] = test_df['D15'] / test_df.groupby(['addr2'])['D15'].transform('mean')\n",
    "test_df['D15_to_std_addr1'] = test_df['D15'] / test_df.groupby(['addr1'])['D15'].transform('std')\n",
    "test_df['D15_to_std_addr2'] = test_df['D15'] / test_df.groupby(['addr2'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train_df['P_emaildomain'].str.split('.', expand=True)\n",
    "train_df[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train_df['R_emaildomain'].str.split('.', expand=True)\n",
    "test_df[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test_df['P_emaildomain'].str.split('.', expand=True)\n",
    "test_df[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test_df['R_emaildomain'].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_cols = [col for col in train_df.columns if train_df[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in test_df.columns if test_df[col].nunique() <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_null_cols = [col for col in train_df.columns if train_df[col].isnull().sum() / train_df.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in test_df.columns if test_df[col].isnull().sum() / test_df.shape[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_top_value_cols = [col for col in train_df.columns if train_df[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in test_df.columns if test_df[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\n",
    "cols_to_drop.remove('isFraud')\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns = cols_to_drop, inplace=True)\n",
    "test_df.drop(columns = cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
       "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
       "       ...\n",
       "       'D15_to_std_card1', 'D15_to_std_card4', 'D15_to_mean_addr1',\n",
       "       'D15_to_mean_addr2', 'D15_to_std_addr1', 'D15_to_std_addr2',\n",
       "       'P_emaildomain_1', 'P_emaildomain_2', 'R_emaildomain_1',\n",
       "       'R_emaildomain_2'],\n",
       "      dtype='object', length=372)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19',\n",
    "            'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27',\n",
    "            'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35',\n",
    "            'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4',\n",
    "            'card6', 'M4','P_emaildomain', 'R_emaildomain', 'card1', 'card2', 'card3',\n",
    "            'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
    "            'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1',\n",
    "            'R_emaildomain_2', 'R_emaildomain_3']\n",
    "\n",
    "drop = ['id_21', 'id_25', 'id_27', 'id_24', 'id_26', 'id_22',\n",
    "        'R_emaildomain_3', 'P_emaildomain_3', 'id_23', 'id_18']\n",
    "\n",
    "\n",
    "for col in drop:\n",
    "    cat_cols.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in train_df.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col].astype(str).values) + list(test_df[col].astype(str).values))\n",
    "        train_df[col] = le.transform(list(train_df[col].astype(str).values))\n",
    "        test_df[col] = le.transform(list(test_df[col].astype(str).values))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.sort_values('TransactionDT').drop(columns = ['isFraud',\n",
    "                                                          'TransactionDT',\n",
    "                                                          'TransactionID'])\n",
    "y = train_df.sort_values('TransactionDT')['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=['TransactionDT', 'TransactionID'])\n",
    "\n",
    "y_test = test_df[[\"TransactionDT\", 'TransactionID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_inf_nan(df):\n",
    "    return df.replace([np.inf, -np.inf], np.nan)   \n",
    "\n",
    "# Cleaning infinite values to NaN\n",
    "X = clean_inf_nan(X)\n",
    "X_test = clean_inf_nan(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplit = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "_,_,_,one = tsplit.split(X)\n",
    "\n",
    "X_train = X.iloc[one[0]]\n",
    "y_train = y.iloc[one[0]]\n",
    "\n",
    "X_val = X.iloc[one[1]]\n",
    "y_val = y.iloc[one[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = lgb.Dataset(X_val, label=y_val, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>D15_to_std_card1</th>\n",
       "      <th>D15_to_std_card4</th>\n",
       "      <th>D15_to_mean_addr1</th>\n",
       "      <th>D15_to_mean_addr2</th>\n",
       "      <th>D15_to_std_addr1</th>\n",
       "      <th>D15_to_std_addr2</th>\n",
       "      <th>P_emaildomain_1</th>\n",
       "      <th>P_emaildomain_2</th>\n",
       "      <th>R_emaildomain_1</th>\n",
       "      <th>R_emaildomain_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>472432</td>\n",
       "      <td>33.261</td>\n",
       "      <td>0</td>\n",
       "      <td>16403</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>441</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472433</td>\n",
       "      <td>52.811</td>\n",
       "      <td>0</td>\n",
       "      <td>15919</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>441</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472434</td>\n",
       "      <td>136.956</td>\n",
       "      <td>0</td>\n",
       "      <td>885</td>\n",
       "      <td>455</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>441</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472435</td>\n",
       "      <td>136.956</td>\n",
       "      <td>0</td>\n",
       "      <td>16729</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>441</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472436</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1</td>\n",
       "      <td>7780</td>\n",
       "      <td>221</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>210</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>49.000</td>\n",
       "      <td>4</td>\n",
       "      <td>13701</td>\n",
       "      <td>501</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269218</td>\n",
       "      <td>0.274035</td>\n",
       "      <td>0.330520</td>\n",
       "      <td>0.306025</td>\n",
       "      <td>0.276139</td>\n",
       "      <td>0.270622</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590536</td>\n",
       "      <td>39.500</td>\n",
       "      <td>4</td>\n",
       "      <td>480</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590537</td>\n",
       "      <td>30.950</td>\n",
       "      <td>4</td>\n",
       "      <td>2207</td>\n",
       "      <td>495</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590538</td>\n",
       "      <td>117.000</td>\n",
       "      <td>4</td>\n",
       "      <td>14954</td>\n",
       "      <td>381</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106296</td>\n",
       "      <td>0.110672</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>0.120224</td>\n",
       "      <td>0.109010</td>\n",
       "      <td>0.106316</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590539</td>\n",
       "      <td>279.950</td>\n",
       "      <td>4</td>\n",
       "      <td>5479</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118108 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionAmt  ProductCD  card1  card2  card3  card4  card5  card6  \\\n",
       "472432          33.261          0  16403      3     85      4     38      2   \n",
       "472433          52.811          0  15919     79      6      4     37      2   \n",
       "472434         136.956          0    885    455     85      4    126      2   \n",
       "472435         136.956          0  16729     30     85      4     38      2   \n",
       "472436          25.000          1   7780    221     50      4    126      2   \n",
       "...                ...        ...    ...    ...    ...    ...    ...    ...   \n",
       "590535          49.000          4  13701    501     50      4    126      2   \n",
       "590536          39.500          4    480    125     50      2    124      2   \n",
       "590537          30.950          4   2207    495     50      2    124      2   \n",
       "590538         117.000          4  14954    381     50      2    124      2   \n",
       "590539         279.950          4   5479     70     50      2      2      1   \n",
       "\n",
       "        addr1  addr2  ...  D15_to_std_card1  D15_to_std_card4  \\\n",
       "472432    441     93  ...          0.000000          0.000000   \n",
       "472433    441     93  ...          0.000000          0.000000   \n",
       "472434    441     93  ...               NaN          0.000000   \n",
       "472435    441     93  ...          0.000000          0.000000   \n",
       "472436    210     80  ...               NaN               NaN   \n",
       "...       ...    ...  ...               ...               ...   \n",
       "590535    172     80  ...          0.269218          0.274035   \n",
       "590536    104     80  ...          0.000000          0.000000   \n",
       "590537    131     80  ...          0.000000          0.000000   \n",
       "590538    287     80  ...          0.106296          0.110672   \n",
       "590539    199     80  ...          0.005348          0.005031   \n",
       "\n",
       "        D15_to_mean_addr1  D15_to_mean_addr2  D15_to_std_addr1  \\\n",
       "472432                NaN                NaN               NaN   \n",
       "472433                NaN                NaN               NaN   \n",
       "472434                NaN                NaN               NaN   \n",
       "472435                NaN                NaN               NaN   \n",
       "472436                NaN                NaN               NaN   \n",
       "...                   ...                ...               ...   \n",
       "590535           0.330520           0.306025          0.276139   \n",
       "590536           0.000000           0.000000          0.000000   \n",
       "590537           0.000000           0.000000          0.000000   \n",
       "590538           0.127389           0.120224          0.109010   \n",
       "590539           0.005946           0.005465          0.004884   \n",
       "\n",
       "        D15_to_std_addr2  P_emaildomain_1  P_emaildomain_2  R_emaildomain_1  \\\n",
       "472432               NaN               15                2               15   \n",
       "472433               NaN               17                6               17   \n",
       "472434               NaN               17                2               17   \n",
       "472435               NaN               17                2               17   \n",
       "472436               NaN               28                2               25   \n",
       "...                  ...              ...              ...              ...   \n",
       "590535          0.270622               25                7               25   \n",
       "590536          0.000000               15                2               25   \n",
       "590537          0.000000               15                2               25   \n",
       "590538          0.106316                2                2               25   \n",
       "590539          0.004833               15                2               25   \n",
       "\n",
       "        R_emaildomain_2  \n",
       "472432                2  \n",
       "472433                6  \n",
       "472434                2  \n",
       "472435                2  \n",
       "472436                7  \n",
       "...                 ...  \n",
       "590535                7  \n",
       "590536                7  \n",
       "590537                7  \n",
       "590538                7  \n",
       "590539                7  \n",
       "\n",
       "[118108 rows x 369 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'num_leaves': 256,\n",
    "#           'min_child_samples': 79,\n",
    "#           'objective': 'binary',\n",
    "#           'max_depth': 13,\n",
    "#           'learning_rate': 0.03,\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"subsample_freq\": 3,\n",
    "#           \"subsample\": 0.9,\n",
    "#           \"bagging_seed\": 11,\n",
    "#           \"metric\": 'auc',\n",
    "#           \"verbosity\": -1,\n",
    "#           'reg_alpha': 0.3,\n",
    "#           'reg_lambda': 0.3,\n",
    "#           'colsample_bytree': 0.9,\n",
    "#           #'categorical_feature': cat_cols\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst = lgb.train(params = params,\n",
    "#                 train_set=train_data,\n",
    "#                 num_boost_round=1000,\n",
    "#                 valid_sets=validation_data,\n",
    "#                 categorical_feature=cat_cols,\n",
    "#                 early_stopping_rounds=200,\n",
    "#                 verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def scores(model, X_train, X_test, y_train, y_test, *args):\n",
    "    '''\n",
    "    input: the model you would like to test, while having train/test split\n",
    "           initialized, normal nomenclature from sklearn train_test_split\n",
    "    \n",
    "    output: dictionary of scores for your model\n",
    "    '''\n",
    "    model_dic = {}\n",
    "    \n",
    "    # make predictions\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # scores for train\n",
    "#     model_dic['train_score'] = model.score(X_train, y_train)\n",
    "#     model_dic['train_precision'] = precision_score(y_train, train_pred)\n",
    "    model_dic['train_recall'] = recall_score(y_train, train_pred)\n",
    "#     model_dic['train_f1'] = f1_score(y_train, train_pred)\n",
    "    model_dic['train_confusion'] = confusion_matrix(y_train, train_pred, labels=[0, 1])\n",
    "    model_dic['train_auc'] = roc_auc_score(y_train, train_pred)\n",
    "    \n",
    "    # scores for test\n",
    "#     model_dic['test_score'] = model.score(X_test, y_test)\n",
    "#     model_dic['test_precision'] = precision_score(y_test, test_pred)\n",
    "    model_dic['test_recall'] = recall_score(y_test, test_pred)\n",
    "#     model_dic['test_f1'] = f1_score(y_test, test_pred)\n",
    "    model_dic['test_confusion'] = confusion_matrix(y_test, test_pred, labels=[0, 1])\n",
    "    model_dic['test_auc'] = roc_auc_score(y_test, test_pred)\n",
    "    \n",
    "    return model_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def percent_confusion(confusion_matrix, title='Confusion Matrix', annot=True, fmt='.2%'):\n",
    "    '''\n",
    "    A fuction to create % of total actual predictions\n",
    "    \n",
    "    input: confusion matrix values\n",
    "    output: seaborn chart of percent of original \n",
    "    '''\n",
    "    \n",
    "    pred_true = confusion_matrix[1][1]\n",
    "    pred_false_neg = confusion_matrix[1][0]\n",
    "    pred_false = confusion_matrix[0][0]\n",
    "    pred_false_pos = confusion_matrix[0][1]\n",
    "\n",
    "    true_actual = confusion_matrix[1].sum()\n",
    "    false_actual = confusion_matrix[0].sum()\n",
    "    \n",
    "    # creating a confusion matrix\n",
    "    confusion = [[pred_false/false_actual, pred_false_pos/false_actual],\n",
    "                 [pred_false_neg/true_actual, pred_true/true_actual]]\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    matrix = sns.heatmap(confusion, vmin=0, vmax=1, cmap='Blues', annot=annot, fmt=fmt)\n",
    "    plt.xlabel('Predicted Values', labelpad=10, fontsize=12)\n",
    "    plt.ylabel('Actual Values', labelpad=10, fontsize=12)\n",
    "    plt.xticks(ticks=[.5,1.5],labels=['Not Fraud', 'Fraud'])\n",
    "    plt.yticks(ticks=[.5,1.5],labels=['Not Fraud', 'Fraud'])\n",
    "    plt.title(title, pad=10, fontsize=15)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(num_leaves= 256,\n",
    "                     min_child_samples= 20,\n",
    "                     objective= 'binary',\n",
    "                     learning_rate= 0.1,\n",
    "                     boosting_type= \"gbdt\",\n",
    "                     subsample_freq= 3,\n",
    "                     subsample= 0.9,\n",
    "                     bagging_seed= 11,\n",
    "                     metric= 'auc',\n",
    "                     verbosity= -1,\n",
    "                     reg_alpha= 0.3,\n",
    "                     reg_lambda= 0.3,\n",
    "                     colsample_bytree= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla\n",
    "# clf = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 2s, sys: 7.27 s, total: 5min 10s\n",
      "Wall time: 46.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_seed=11, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=0.9, importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, metric='auc', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=256, objective='binary', random_state=None,\n",
       "               reg_alpha=0.3, reg_lambda=0.3, silent=True, subsample=0.9,\n",
       "               subsample_for_bin=200000, subsample_freq=3, verbosity=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(train_data.data,\n",
    "        train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_scores = scores(clf, train_data.data, validation_data.data, train_data.label, validation_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_recall': 0.771070546418459, 'train_confusion': array([[455702,    131],\n",
       "        [  3800,  12799]]), 'train_auc': 0.8853915802339513, 'test_recall': 0.37450787401574803, 'test_confusion': array([[113685,    359],\n",
       "        [  2542,   1522]]), 'test_auc': 0.685679983095349}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred = clf.predict(train_data.data)\n",
    "val_pred = clf.predict(validation_data.data)\n",
    "train_proba = clf.predict_proba(train_data.data)\n",
    "val_proba = clf.predict_proba(validation_data.data)\n",
    "\n",
    "# \n",
    "merge_df = train_data.data.append(validation_data.data)\n",
    "\n",
    "train_pred = pd.DataFrame(train_pred, columns = ['predictions'])\n",
    "val_pred = pd.DataFrame(val_pred, columns=['predictions'])\n",
    "pred = train_pred.append(val_pred)\n",
    "\n",
    "train_proba = pd.DataFrame(train_proba, columns = ['not_fraud', 'fraud'])\n",
    "val_proba = pd.DataFrame(val_proba, columns=['not_fraud', 'fraud'])\n",
    "pred_proba = train_proba.append(val_proba)\n",
    "\n",
    "pred.index = merge_df.index\n",
    "pred_proba.index = merge_df.index\n",
    "\n",
    "pred = pred.merge(pred_proba, left_index=True, right_index=True)\n",
    "# del pred_proba, pred_proba, train_pred, val_pred, train_proba, val_proba\n",
    "\n",
    "merge_df = merge_df.merge(pred, left_index=True, right_index=True)\n",
    "\n",
    "merge_df = merge_df[['predictions', 'not_fraud', 'fraud']]\n",
    "\n",
    "train_df = train_df.merge(merge_df, left_index=True, right_index=True)\n",
    "\n",
    "test = train_df.drop(columns=[x for x in train_df.columns if 'id_' in x and x not in [f'id_{x}' for x in range(29,34)]])\n",
    "\n",
    "test = test.drop(columns=[x for x in test.columns if 'V' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('predictions_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada_train = pd.read_pickle('X_train')\n",
    "y_ada_train = pd.read_pickle('y_train')\n",
    "X_ada_test = pd.read_pickle('X_test')\n",
    "y_ada_test = pd.read_pickle('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.5 s, sys: 963 ms, total: 52.4 s\n",
      "Wall time: 8.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_ada_train,\n",
    "        y_ada_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_scores = scores(clf, X_ada_train, X_ada_test, y_ada_train, y_ada_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_recall': 0.9536834232597895,\n",
       " 'train_confusion': array([[423907,   3501],\n",
       "        [ 19941, 410596]]),\n",
       " 'train_auc': 0.9727460933915837,\n",
       " 'test_recall': 0.4618660472319009,\n",
       " 'test_confusion': array([[141165,   1304],\n",
       "        [  2780,   2386]]),\n",
       " 'test_auc': 0.726356589444306}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_ada_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
